from langchain_groq import ChatGroq
from typing_extensions import Annotated, TypedDict

api_key = "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"


class LlmResponse(TypedDict):
    response: Annotated[str, ..., "The model's response"]
    source: Annotated[str, ..., "The source of the context"]


def create_and_run_chain(context, user_input):
    llm = ChatGroq(
        model="mixtral-8x7b-32768",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
        api_key=api_key
    )
    messages = [
        (
            "system",
            f"You are a helpful assistant which is assigned to answer the user question "
            f"based on this contex provided: {context['page_content']}."
            f"The output should also include:"
            f"a title generated by yourself about the document, which should be no longer than 5 words."
            f"and the source of the information: {context['source']}",
        ),
        ("human", user_input),
    ]
    structured_llm = llm.with_structured_output(LlmResponse)
    ai_msg = structured_llm.invoke(messages)
    print("LLM RES", ai_msg)

